# A High-Quality Robust Diffusion Framework for Corrupted Dataset #

Developing image-generative models, which are robust to outliers in the training process, has recently drawn attention from the research community. Due to the ease of integrating unbalanced optimal transport (UOT) into adversarial framework, existing works focus mainly on developing robust frameworks for generative adversarial model (GAN). Meanwhile, diffusion models have recently dominated GAN in various tasks and datasets. However, according to our knowledge, none of them are robust to corrupted datasets. Motivated by DDGAN, our work introduces the first robust-to-outlier diffusion. We suggest replacing the UOT-based generative model for GAN in DDGAN to learn the backward diffusion process. Additionally, we demonstrate that the Lipschitz property of divergence in our framework contributes to more stable training convergence. Remarkably, our method not only exhibits robustness to corrupted datasets but also achieves superior performance on clean datasets.

## Set up datasets ##
We trained on several datasets, including CIFAR10, LSUN Church Outdoor 256, CelebA HQ 256, MNIST. 

## Set up environment ##
First, install Pytorch v1.12.1:
```
pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116
```
Then, install other modules using:
```
pip install -r requirements.txt
```
Upgrade some modules to solve 'safetensors' has no attribute 'torch':
pip install --upgrade diffusers transformers accelerate scipy ftfy safetensors

## Training RDUOT ##
We use the following commands for training our proposed model.

#### CIFAR-10 pertubed by MNIST (5%) ####

We train RDUOT using 1 32-GB V100 GPU. 
```
python3 train.py --dataset cifar10 --exp ddgan_cifar10_exp1 --num_channels 3 --num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --batch_size 64 --num_epoch 1800 --ngf 64 --nz 100 --z_emb_dim 256 --n_mlp 4 --embedding_type positional --use_ema --ema_decay 0.9999 --r1_gamma 0.02 --lr_d 1.25e-4 --lr_g 1.6e-4 --lazy_reg 15 --num_process_per_node 1 --ch_mult 1 2 2 2 --save_content --version bs256 --master_port 6021 --phi1 softplus --phi2 softplus --perturb_dataset mnist --perturb_percent 5
```

## Evaluation ##
After training, samples can be generated by calling ```test.py```. 
Below, we use `--epoch_id` to specify the checkpoint saved at a particular epoch.
Specifically, for models trained by above commands, the scripts for generating samples on CIFAR-10 (DDGAN) is
```
python3 test.py --dataset cifar10 --num_channels 3 --num_channels_dae 128 --num_timesteps 4 --batch_size 1800 --num_res_blocks 2 --nz 100 --z_emb_dim 256 --n_mlp 4 --ch_mult 1 2 2 2 --version bs256 --master_port 6038 --compute_fid --epoch_start 1100 --epoch_end 1800 --epoch_jump 25 --phi1 softplus --phi2 softplus --perturb_dataset mnist --perturb_percent 5
```

Note: Remove `--perturb_dataset` and `--perturb_percent` for a clean training dataset.

We use the [PyTorch](https://github.com/mseitzer/pytorch-fid) implementation to compute the FID scores, and in particular, codes for computing the FID are adapted from [FastDPM](https://github.com/FengNiMa/FastDPM_pytorch).

To compute FID, run the same scripts above for sampling, with additional arguments ```--compute_fid```.

Code for computing Inception Score is adapted from [here](https://github.com/tsc2017/Inception-Score).

For Improved Precision and Recall, follow the instruction [here](https://github.com/kynkaat/improved-precision-and-recall-metric).